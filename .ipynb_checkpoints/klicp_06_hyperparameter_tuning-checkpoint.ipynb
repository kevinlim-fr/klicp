{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64e1318-0afd-49a5-a7d5-ea794c0df032",
   "metadata": {},
   "source": [
    "# <b> Hyperparameter Tuning using hyperopt / MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afebcf73-95f8-460e-b8d9-2ad10edc2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import mlflow, sys\n",
    "from xgboost import XGBRegressor, XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e93b20-398c-4493-a595-30a87653eb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74579a0-267e-46bf-8d8f-2cf9c483553a",
   "metadata": {},
   "source": [
    "## <b> Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9d5c2-63fe-41ce-99f1-b0410072bccd",
   "metadata": {},
   "source": [
    "### create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da286aaf-211c-4dd1-9d4d-c55f7e7d0f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(algo, params):\n",
    "    '''\n",
    "    algo : string\n",
    "        algo is a string to choose the right model. To implement a new model, define algo, add log model mlflow\n",
    "        \n",
    "    params: params\n",
    "        Params are passed from the definitions above\n",
    "    '''\n",
    "    if algo == 'XGBRegressor':\n",
    "        model = XGBRegressor(**params, n_jobs=-1, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        # Log the model into mlflow\n",
    "        mlflow.xgboost.log_model(model, algo)\n",
    "    \n",
    "    elif algo == 'XGBClassifier':\n",
    "        model = XGBClassifier(**params, n_jobs=-1, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        # Log the model into mlflow\n",
    "        mlflow.xgboost.log_model(model, algo)\n",
    "    \n",
    "    elif algo == 'RandomForestRegressor':\n",
    "        model = RandomForestRegressor(**params, n_jobs=-1, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model, algo)\n",
    "    \n",
    "    elif algo == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(**params, n_jobs=-1, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model, algo)\n",
    "    \n",
    "    elif algo == 'LinearRegression':\n",
    "        model = LinearRegression(**params, n_jobs=-1, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model, algo)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ee06c-77b1-4ccc-9c05-27b1069ddc94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### objective_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c598a29-1b2d-47e9-bf89-40e1e3796b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_function(params, algo, mode, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Objective function for Hyperparmeter optimisation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : parameters\n",
    "        Pass the parameters into the model creation and into the mlflow metrics\n",
    "    algo : string\n",
    "        Name of the algorithm 'XGBoost','XGBoostBinary','SVM','RandomForest', 'DecisionTree'\n",
    "    X_train, X_test, y_train, y_test : pd.DataFrame\n",
    "        Data for ML\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        loss value\n",
    "    '''\n",
    "    \n",
    "    with mlflow.start_run(run_name = algo):\n",
    "        # Recover the parameters and create the model\n",
    "        model = create_model(algo, params)\n",
    "        \n",
    "        # Log Metrics and Params\n",
    "        for k, v in params.items():        \n",
    "            mlflow.log_param(k, v)\n",
    "\n",
    "        #Predict the value\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        # If Classification\n",
    "        if mode.lower() == 'classification':\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            #auc_roc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "            mlflow.log_metric(\"acc\", acc)\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "            mlflow.log_metric(\"f1\", f1)\n",
    "            #mlflow.log_metric(\"auc_roc\", auc_roc)\n",
    "            loss = -f1\n",
    "    \n",
    "        # Time series\n",
    "        elif mode.lower() == 'time_series':\n",
    "            mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"mape\", mape)\n",
    "            loss = rmse\n",
    "    \n",
    "        # Regression\n",
    "        elif mode.lower() == 'regression' :\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_metric(\"r2\", r2)\n",
    "            loss = rmse\n",
    "        return {'loss': loss , 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf57e0-423b-47e1-8ff0-0748ef2039f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### convert_best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ca1c9cca-f878-4d58-8c2f-8319d645b297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_best_param(best_param, space):\n",
    "    best_param_converted = {}\n",
    "    for key,value in spaces[algo].items():\n",
    "        #print(key,value)\n",
    "        if value.name=='switch':\n",
    "            best_param_converted[key] = space[key].pos_args[1+best_param[key]].obj\n",
    "        elif value.name == 'int':\n",
    "            best_param_converted[key] = int(best_param[key])\n",
    "        else:\n",
    "            best_param_converted[key] = best_param[key]\n",
    "    return best_param_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f16005-2aae-4e7e-836f-eee577bb8cf3",
   "metadata": {},
   "source": [
    "## <b> Large Search Space Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80662bd3-e87f-4fe5-9134-a70744148b67",
   "metadata": {},
   "source": [
    "### <b> How to define a search space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f18669-e06c-423c-afc1-08629bf4e7f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### hp.uniform(): \n",
    "This function generates a value from a uniform distribution between a lower and upper bound. Use this distribution if the hyperparameter has a wide range of possible values and there is no reason to believe that certain values are more likely to be optimal than others.\n",
    "\n",
    "#### hp.loguniform(): \n",
    "This function generates a value from a log-uniform distribution between a lower and upper bound. Use this distribution if the hyperparameter has a wide range of possible values that span several orders of magnitude, and there is reason to believe that smaller values may be more optimal than larger values.\n",
    "\n",
    "#### hp.quniform(): example : quniform('param', 0, 10, 2) -> [0, 2, 4, 6, 8, 10]\n",
    "This function generates a value from a uniform distribution between a lower and upper bound, with a fixed step size. Use this distribution if the hyperparameter should be sampled from a discrete set of values, and the range of possible values is known in advance.\n",
    "\n",
    "#### hp.qloguniform(): qloguniform('param', 0, 10, 2) -> [1, 10, 100]\n",
    "This function generates a value from a quantized log-uniform distribution between a lower and upper bound, with a fixed step size. Use this distribution if the hyperparameter should be sampled from a discrete set of values that span several orders of magnitude, and the range of possible values is known in advance.\n",
    "\n",
    "#### hp.choice(): \n",
    "This function generates a value by choosing one of the specified options. Use this distribution if the hyperparameter should take on a small number of distinct values, and the set of possible values is known in advance.\n",
    "\n",
    "#### hp.normal(): \n",
    "This function generates a value from a normal distribution with a specified mean and standard deviation. Use this distribution if the hyperparameter is expected to have a bell-shaped distribution, and there is reason to believe that certain values are more likely to be optimal than others.\n",
    "\n",
    "#### hp.qnormal(): \n",
    "This function generates a value from a normal distribution with a specified mean and standard deviation, rounded to the nearest multiple of a specified step size. Use this distribution if the hyperparameter should take on a discrete set of values that follow a bell-shaped distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77516923-9c63-4999-a7c3-887aa85530cc",
   "metadata": {},
   "source": [
    "### <b> Feature Dictionnary (common to multiple algorihtms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00e59d52-19d0-4f8d-a1f0-26b243f31746",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dic = {\n",
    "    #Random forest\n",
    "    'criterion' : [\"squared_error\", \"poisson\"],\n",
    "    'max_features' : ['auto','sqrt','log2'],\n",
    "    \n",
    "    #XGBoost\n",
    "    'tree_method' : ['auto','exact','approx','hist']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64ead5c9-cd7e-4232-b353-e672170481d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spaces = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2eeae9-61c3-44d7-a682-dee793638349",
   "metadata": {},
   "source": [
    "### <b> XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14014fff-d15f-42f5-bf28-4c448b8392f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29e673-5c27-4ed4-bfd2-1037086207cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor_params = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(1)),\n",
    "    'gamma': hp.loguniform('gamma', np.log(0.001), np.log(3)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 10, 50, 1)),\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 7, 1)),\n",
    "    \n",
    "    'max_delta_step': scope.int(hp.quniform('max_delta_step', 1, 7, 1)),\n",
    "    'subsample': hp.loguniform('subsample', np.log(0.001), np.log(1)),\n",
    "    'colsample_bytree': hp.loguniform('colsample_bytree', np.log(0.001), np.log(1)),\n",
    "    'colsample_bylevel': hp.loguniform('colsample_bylevel', np.log(0.001), np.log(1)),\n",
    "    'colsample_bynode': hp.loguniform('colsample_bynode', np.log(0.001), np.log(1)),\n",
    "    \n",
    "    'lambda': hp.loguniform('lambda', np.log(0.0001), np.log(1)),\n",
    "    'alpha': hp.loguniform('alpha', np.log(0.0001), np.log(1)),\n",
    "    'tree_method': hp.choice('tree_method',['auto','exact','approx','hist'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eab1d8-7b29-4607-b124-ee14839596b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d44c055d-1311-40a5-ad19-df402410d7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_values =  [\"binary:logistic\", \"binary:logitraw\", \"binary:hinge\"]\n",
    "eval_metric_values =  ['logloss', 'error', 'auc', 'merror', 'mlogloss']\n",
    "booster_values = ['gbtree', 'gblinear', 'dart']\n",
    "tree_method_values = ['auto']\n",
    "\n",
    "XGBClassifier_params = {\n",
    "    # objective\n",
    "    # Regression : \"reg:squarederror\", \"reg:squaredlogerror\", \"reg:logistic\"\n",
    "    # Binary classification : \"binary:logistic\", \"binary:logitraw\", \"binary:hinge\"\n",
    "    # Multiclass classification : \"multi:softmax\", \"multi:softprob\"\n",
    "    'objective': hp.choice('objective', objective_values),\n",
    "    # Eval Metric \n",
    "    # Regression (rmse, mae, logloss)\n",
    "    # Binary classification (error, auc, aucpr, rmse, mae, logloss)\n",
    "    # Multiclass classification (merror, mlogloss, auc, aucpr, rmse, mae, logloss)\n",
    "    'eval_metric': hp.choice('eval_metric',eval_metric_values),\n",
    "    # Booster\n",
    "    'booster': hp.choice('booster', booster_values),\n",
    "    # Eta / Learning rate\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    # Gamma / Min split loss\n",
    "    'gamma': scope.int(hp.qloguniform('gamma', 0, 5, 1)),\n",
    "    # Max Depth\n",
    "    'max_depth': scope.int(hp.choice('max_depth', range(1, int(1e3), 1))),\n",
    "    # Min Child Weight\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, int(1e3), 1)),\n",
    "    #Max Delta Step\n",
    "    'max_delta_step': scope.int(hp.quniform('max_delta_step', 0, int(1e3), 1)),\n",
    "    # Subsample\n",
    "    'subsample': hp.uniform('subsample', 1e-6, 1),\n",
    "    # col\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 1e-6, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 1e-6, 1),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 1e-6, 1),\n",
    "    # Lambda (temp)\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -5, 0),\n",
    "    # Alpha\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, 0),\n",
    "    # Tree Method ('exact', 'approx', 'hist', 'gpu_hist')\n",
    "    'tree_method': hp.choice('tree_method', ['auto']),\n",
    "    # Scale Pos Weight\n",
    "    'scale_pos_weight': hp.quniform('scale_pos_weight', 1, int(1e3), 1),\n",
    "    # Max leaves\n",
    "    'max_leaves': scope.int(hp.quniform('max_leaves', 0, int(1e3), 1)),\n",
    "    \n",
    "    # sketch_eps, updater, refresh_leaf, process_type, grow_policy\n",
    "    #'n_estimators': hp.choice('n_estimators', range(100, 1000, 50)),\n",
    "    #'grow_policy': hp.choice('grow_policy', ['depthwise', 'lossguide']),\n",
    "    #'num_class': hp.choice('num_class', [2, 3, 4, 5, 6, 7, 8, 9, 10]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62fc82fc-9228-4e5c-a656-c0ad224c6ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spaces[\"XGBClassifier\"] = XGBClassifier_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c62deb-509d-4649-ad5a-3688e480c194",
   "metadata": {},
   "source": [
    "### <b> RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c270e-3d1e-4cef-be1d-5117e10df110",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27240126-6bd1-4d4c-b1b7-3e2d1ed4927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier_params = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 1000, 1)),\n",
    "    'criterion': hp.choice('criterion', feature_dic['criterion']),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 2, 1000, 1)),\n",
    "    'min_samples_split': hp.loguniform('min_samples_split', np.log(sys.float_info.min), np.log(0.3)),\n",
    "    'min_samples_leaf': hp.loguniform('min_samples_leaf', np.log(sys.float_info.min), np.log(0.3)),\n",
    "    'min_weight_fraction_leaf': hp.loguniform('min_weight_fraction_leaf', np.log(sys.float_info.min), np.log(0.5)),\n",
    "    'max_features': hp.choice('max_features', feature_dic['max_features']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da2c47-41bf-4699-9060-4e5b510845f4",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b146bb-b5f7-4570-a0de-ef34022c3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor_params = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(1,100)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'max_depth': hp.choice('max_depth', range(1,100)),\n",
    "    'min_samples_split': hp.loguniform('min_samples_split', np.log(0.00001), np.log(0.5)),\n",
    "    'min_samples_leaf': hp.loguniform('min_samples_leaf', np.log(0.00001), np.log(0.5)),\n",
    "    'max_features': hp.choice('max_features',['auto','sqrt','log2'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82e797-a475-4d55-b4ec-1ef69c97e435",
   "metadata": {},
   "source": [
    "### <b> GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afa7c1-42dc-4d28-a46d-aa6317b1043a",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf049912-8ab6-4c74-aaf9-daa437d41b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GradientBoostingRegressor_params = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 1, 2000, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    'max_depth': hp.choice('max_depth', range(3, 11)),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 21)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 21)),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n",
    "    'loss': hp.choice('loss', ['deviance', 'exponential']),\n",
    "    'criterion': hp.choice('criterion', ['mse', 'friedman_mse']),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', [None, 5, 10, 20, 50]),\n",
    "    'min_impurity_decrease': hp.loguniform('min_impurity_decrease', -15, 0),\n",
    "    'init': hp.choice('init', [None, 'zero', 'mean'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5201901-26f4-4f5c-a0d1-2692b82583b4",
   "metadata": {},
   "source": [
    "### <b> Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5c606-37bd-4034-af53-d054f843a393",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ac3f0a-952b-4dbe-995e-c2db46c910bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m SVR_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mhp\u001b[49m\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1000\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m      5\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "SVR_params = {\n",
    "    'C': hp.loguniform('C', np.log(1), np.log(1000)),\n",
    "    'kernel': hp.choice('kernel', ['linear', 'rbf']),\n",
    "    'gamma': hp.loguniform('gamma', np.log(1), np.log(1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9ef7c-05fc-407d-9538-1bf5f66bf7d6",
   "metadata": {},
   "source": [
    "### <b> DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5e7dc-389b-44de-9caf-acd41d8fa958",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcfc905-2bb8-41c2-8adf-ecec215881ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfce4e4-8a86-4021-9e84-c5000eb5f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeRegressor_params = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
